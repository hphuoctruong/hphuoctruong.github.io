---
title: Appendix. Probability Theory - A simple approach.
author: Phuoc-Truong Huynh
date: 2021-07-15 12:00:00 +0200
categories: [Seminar]
tags: [inverse problems, bayesian, optimization]
toc: true
math: true
pin: true
---

## **Basic concepts**

A **probability space** is a triplet $$(\Omega, \mathcal{F}, \mathbb{P})$$, where $$\Omega$$ is the sample space, $$\mathcal{F}$$ is a $$\sigma-$$ algebra of events and $$\mathbb{P}$$ is a probability measure on $$\Omega$$.

Let $$(E,\mathbb{B}(E))$$ be a measurable space, where $$\mathbb{B}(E)$$ denotes the Borel $$\sigma-$$ algebra generated by the open sets of $$E$$.

A measurable mapping $$X: \Omega \to E$$ is a random variable. This random variable induces a probability measure $$\mu$$ on $$E$$ given by

$$\mu_X(A):= \mathbb{P}(X^{-1}(A)) = \mathbb{P}\left(\left\{\omega \in \Omega: X(\omega) \in A\right\}\right),\quad A \in \mathbb{B}(E).$$

The measure $$\mu_X$$ is called the **probability distribution** of $$u$$ and we write $$X \sim \mu_X$$. We note that $$\mu_X$$ is also called the push-forward of $$\mathbb{P}$$ via $$X$$ and is denoted by $$X_*\mathbb{P}$$.

In this note, we use the notations $$X,Y, u, y, \ldots$$ to denote random variables.


We write

$$\int X(\omega) d \mathbb{P}(\omega), \text{ or } \int X(\omega) \mathbb{P}(d\omega).$$

**Theorem.**

Let $$(\Omega_1, \mathcal{F}_1)$$ and $$(\Omega_2,\mathcal{F}_2)$$ be measurable spaces and let $$\mu$$ be a measure on $$(\Omega_1, \mathcal{F}_1)$$. Assume that $$X: \Omega_1 \to \Omega_2$$ is a measurable map and $$X_*\mu$$ the push-forward measure. If $$f \in L^1(\Omega_2,d X_* \mu)$$, then $$f \circ X \in L^1(\Omega_1,d\mu)$$ and

$$\int_{\Omega_1}(f \circ X) d\mu = \int_{\Omega_2} f d(X_* \mu).$$

In particular, if $$X$$ is a random variable on $$(\Omega, \mathcal{F}, \mathbb{P})$$, then

$$\int f(x) \mathbb{P}(X \in dx):= \int f(x) dX_*\mathbb{P}(x) = \int f\circ X(\omega) d P(\omega).$$

**Proposition.**
Let $$\mu_1$$ and $$\mu_2$$ be two $$\sigma-$$ finite measures on $$\mathbb{R}^n$$ defined over the Borel $$\sigma-$$ algebra of $$\mathbb{R}^n$$ such that $$\mu_1 \ll \mu_2$$. Then there exists a measurable function $$\pi: \mathbb{R}^n \to \mathbb{R}$$ such that
$$\mu_1(B) = \int_{B} \pi(x)d\mu_2(x),\quad \forall B \in \mathbb{B}(\mathbb{R^n}).$$

The function $$\pi$$ is called the Radon-Nikodym derivative of $$\mu_1$$ with respect to $$\mu_2$$, denoted by

$$\pi = \dfrac{d\mu_1}{d\mu_2}.$$

It can be seen that



## **Joint probability distributions.**

Let $$X_1 : \Omega \to \mathbb{R}^m$$ and $$X_2 : \Omega \to \mathbb{R}^n$$ be two random variables. The joint probability distribution of $$(X_1,X_2)$$ is the probability distribution $$\mu_{X_1 X_2}$$ of the product random variables
$$X_1 \times X_2: \Omega \to \mathbb{R}^m \times \mathbb{R}^n, \quad \omega \mapsto (X_1(\omega),X_2(\omega)),$$
i.e.
$$\mu_{X_1X_2}(B_1,B_2) = \mathbb{P}(X_1^{-1}(B_1) \cap X_2^{-1}(B_2))$$
for all $$B_1 \in \mathbb{B}(\mathbb{R^m}), B_2 \in \mathbb{B}(\mathbb{R^n}).$$


## **Conditional probabilities and conditional distributions.**

Let $$X_1 : \Omega \to \mathbb{R}^m$$ and $$X_2 : \Omega \to \mathbb{R}^n$$ be two random variables. Denote by $$\mu_{X_1X_2}$$ the joint probability distribution of $$(X_1,X_2)$$. The aim of this section is to find the probability distribution of $$X_2$$ when $$X_1$$ is given.


 Assume that $$\mu_{X_1X_2}$$ admits a density function $$\pi_{X_1 X_2}: \mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}$$. We have

$$\mu_{X_1 X_2}(B_1,B_2) = \int_{B_1 \times B_2} \pi_{X_1 X_2}(x_1,x_2)d x_1 dx_2, \quad \forall B_1 \times B_2 \in \mathbb{B}(\mathbb{R}^m)\times \mathbb{B}(\mathbb{R}^n).$$

**Definition.** The marginal density of $$X_1$$ is the the probability distribution of $$X_1$$ when $$X_2$$ may take on any value, i.e.,

$$\mu_{X_1}(B_1):= \mu_{X_1 X_2}(B_1,\mathbb{R}^n),\quad \forall B_1 \in \mathbb{B}(\mathbb{R^m}).$$

In this case, one has

$$\mu_{X_1}(B_1):= \int_{B_1} \int_{\mathbb{R}^n} \pi_{X_1X_2}(x_1,x_2)dx_2 dx_1. \label{eq:eq1}\tag{1}$$

If we denoted

$$\pi_{X_1}(x_1):= \int_{\mathbb{R}^n} \pi_{X_1 X_2} (x_1,x_2) dx_2,$$

then by \eqref{eq:eq1} can write
$$\mu_{X_1}(B_1) = \int_{B_1} \pi_{X_1}(x_1)d x_1, \quad \forall B_1 \in \mathbb{B}(\mathbb{R}^m)$$

In other words, $$\pi_{X_1}$$ is the probability density function of $$\mu_{X_1}$$.


> Overthinking.
> ABC.
